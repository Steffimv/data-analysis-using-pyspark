# ğŸ” Data Analysis Using PySpark â€“ Guided Project

This repository contains a Colab notebook demonstrating large-scale data analysis using PySpark and Spark SQL.
---

## ğŸ“š About the Project

This hands-on project introduces the use of **Apache Spark with Python (PySpark)** for analyzing large-scale datasets. The project walks through:

- Setting up PySpark in a Colab environment
- Loading and inspecting data using Spark DataFrames
- Data wrangling and preprocessing with Spark APIs
- Performing exploratory data analysis (EDA)
- Grouping, filtering, and summarizing large datasets
- Writing Spark SQL queries for analysis

---

## ğŸš€ Technologies Used

- Python 3.x  
- Apache Spark  
- PySpark  
- Google Colab  
- Spark SQL  

---

## ğŸ““ Contents

| File | Description |
|------|-------------|
| `Data Analysis using PySpark(c).ipynb` | Colab notebook covering the full guided PySpark data analysis project. |
| `dataset` | Contains the dataset used for this project |

---

## ğŸ“Œ How to Run

To view or run the notebook:

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/data-analysis-using-pyspark.git
2. Open the notebook in Google Colab.
3. Follow the steps in the notebook to set up PySpark and run the analysis.
